---
title: Predict the Criminals
author: Gaurav Satav
date: '2018-02-05'
slug: predict-the-criminals
categories:
  - machinelearning
  - R
tags:
  - competition
  - hackerearth
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: flatly
    code_folding: hide
---



<div class="figure">
<img src="https://upsideinnovations.com/wp-content/uploads/2017/04/prisoner-jail.jpg" />

</div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Decision which we make are a direct results of the experience we’ve gained over our lifetime and of many factors which led us to those experiences there are certain factors which contributed more than others. There is a greater chance of two individuals making similar decisions if they’ve had similar experiences which were driven by similar factors. In this problem we’ll try to determine those relations between factors and decsion which led to individuals to commit a crime.</p>
<p>The data set for this particular problem is available <a href="https://www.hackerearth.com/challenge/competitive/predict-the-criminal/">here</a></p>
<p>We are given 2 files:</p>
<ul>
<li><strong>criminal_train</strong></li>
<li><strong>criminal_test</strong></li>
</ul>
<p>The <code>criminal_train</code> dataset consist of answer to <strong>71</strong> variables which are related to the private information of around <strong>45718</strong> individuals. The last column in this dataset <code>Criminal</code> consist of either <strong>1</strong> or <strong>0</strong> and indicates whether they commited crime at some point in time. Similarly the <code>criminal_test</code> dataset contains the answers to same variables as that of <code>criminal_train</code> except that it doesen’t contain the last column <code>Criminal</code> and our job is to build up a model to predict the same.</p>
</div>
<div id="preparation" class="section level1 tabset tabset-fade tabset-pills">
<h1>Preparation</h1>
<div id="importing-libraries" class="section level2">
<h2>Importing Libraries</h2>
<p>We’ll make use of mutiple R libraries for visualization and to handle data. Click on <em>show code</em> to see the libraries we’re required to import.</p>
<pre class="r"><code># Data Handling
library(dplyr)

# Visualization
library(ggplot2)
library(knitr)
library(kableExtra)
library(corrplot) #used for plotting co-relations.

# Machine Learning Libraries
library(randomForest)
library(caret)
library(glmnet)
library(gbm)
library(mlbench)
library(caTools)</code></pre>
</div>
</div>
<div id="overview-understanding-the-file-structure." class="section level1 tabset tabset-fade tabset-pills">
<h1>Overview : Understanding the file structure.</h1>
<div id="what-do-the-variables-mean" class="section level2">
<h2>What do the variables mean?</h2>
<p>The table below shows us the meaning of the variables.</p>
<pre class="r"><code>VariableMeaning &lt;- read.csv(&quot;~/Desktop/ME/MyWebsites/Blog2/data/Criminal/Data/var.csv&quot;)
VariableMeaning %&gt;% kable(format = &quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;,&quot;hover&quot;,&quot;condensed&quot;))</code></pre>
<table class="table table-striped table-hover table-condensed" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Variable.Name
</th>
<th style="text-align:left;">
Description
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
PERID
</td>
<td style="text-align:left;">
Person ID
</td>
</tr>
<tr>
<td style="text-align:left;">
IFATHER
</td>
<td style="text-align:left;">
FATHER IN HOUSEHOLD
</td>
</tr>
<tr>
<td style="text-align:left;">
NRCH17_2
</td>
<td style="text-align:left;">
RECODED # R’s CHILDREN &lt; 18 IN HOUSEHOLD
</td>
</tr>
<tr>
<td style="text-align:left;">
IRHHSIZ2
</td>
<td style="text-align:left;">
RECODE - IMPUTATION-REVISED # PERSONS IN HH
</td>
</tr>
<tr>
<td style="text-align:left;">
IIHHSIZ2
</td>
<td style="text-align:left;">
IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
IRKI17_2
</td>
<td style="text-align:left;">
IMPUTATION-REVISED # KIDS AGED&lt;18 IN HH
</td>
</tr>
<tr>
<td style="text-align:left;">
IIKI17_2
</td>
<td style="text-align:left;">
IRKI17_2-IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
IRHH65_2
</td>
<td style="text-align:left;">
REC - IMPUTATION-REVISED # OF PER IN HH AGED&gt;=65
</td>
</tr>
<tr>
<td style="text-align:left;">
IIHH65_2
</td>
<td style="text-align:left;">
IRHH65_2-IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
PRXRETRY
</td>
<td style="text-align:left;">
SELECTED PROXY UNAVAILABLE
</td>
</tr>
<tr>
<td style="text-align:left;">
OTHER PROXY AVAILABLE?
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
PRXYDATA
</td>
<td style="text-align:left;">
IS PROXY ANSWERING INSURANCE/INCOME QS
</td>
</tr>
<tr>
<td style="text-align:left;">
MEDICARE
</td>
<td style="text-align:left;">
COVERED BY MEDICARE
</td>
</tr>
<tr>
<td style="text-align:left;">
CAIDCHIP
</td>
<td style="text-align:left;">
COVERED BY MEDICAID/CHIP
</td>
</tr>
<tr>
<td style="text-align:left;">
CHAMPUS
</td>
<td style="text-align:left;">
COV BY TRICARE
</td>
</tr>
<tr>
<td style="text-align:left;">
CHAMPUS
</td>
<td style="text-align:left;">
CHAMPVA
</td>
</tr>
<tr>
<td style="text-align:left;">
VA
</td>
<td style="text-align:left;">
MILITARY
</td>
</tr>
<tr>
<td style="text-align:left;">
PRVHLTIN
</td>
<td style="text-align:left;">
COVERED BY PRIVATE INSURANCE
</td>
</tr>
<tr>
<td style="text-align:left;">
GRPHLTIN
</td>
<td style="text-align:left;">
PRIVATE PLAN OFFERED THROUGH EMPLOYER OR UNION
</td>
</tr>
<tr>
<td style="text-align:left;">
HLTINNOS
</td>
<td style="text-align:left;">
COVERED BY HEALTH INSUR
</td>
</tr>
<tr>
<td style="text-align:left;">
HLCNOTYR
</td>
<td style="text-align:left;">
ANYTIME DID NOT HAVE HEALTH INS/COVER PAST 12 MOS
</td>
</tr>
<tr>
<td style="text-align:left;">
HLCNOTMO
</td>
<td style="text-align:left;">
PAST 12 MOS
</td>
</tr>
<tr>
<td style="text-align:left;">
HOW MANY MOS W/O COVERAGE
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
HLCLAST
</td>
<td style="text-align:left;">
TIME SINCE LAST HAD HEALTH CARE COVERAGE
</td>
</tr>
<tr>
<td style="text-align:left;">
HLLOSRSN
</td>
<td style="text-align:left;">
MAIN REASON STOPPED COVERED BY HEALTH INSURANCE
</td>
</tr>
<tr>
<td style="text-align:left;">
HLNVCOST
</td>
<td style="text-align:left;">
COST TOO HIGH
</td>
</tr>
<tr>
<td style="text-align:left;">
HLNVOFFR
</td>
<td style="text-align:left;">
EMPLOYER DOESN’T OFFER
</td>
</tr>
<tr>
<td style="text-align:left;">
HLNVREF
</td>
<td style="text-align:left;">
INSURANCE COMPANY REFUSED COVERAGE
</td>
</tr>
<tr>
<td style="text-align:left;">
HLNVNEED
</td>
<td style="text-align:left;">
DON’T NEED IT
</td>
</tr>
<tr>
<td style="text-align:left;">
HLNVSOR
</td>
<td style="text-align:left;">
NEVER HAD HLTH INS SOME OTHER REASON
</td>
</tr>
<tr>
<td style="text-align:left;">
IRMCDCHP
</td>
<td style="text-align:left;">
IMPUTATION REVISED CAIDCHIP
</td>
</tr>
<tr>
<td style="text-align:left;">
IIMCDCHP
</td>
<td style="text-align:left;">
MEDICAID/CHIP - IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
IRMEDICR
</td>
<td style="text-align:left;">
MEDICARE - IMPUTATION REVISED
</td>
</tr>
<tr>
<td style="text-align:left;">
IIMEDICR
</td>
<td style="text-align:left;">
MEDICARE - IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
IRCHMPUS
</td>
<td style="text-align:left;">
CHAMPUS - IMPUTATION REVISED
</td>
</tr>
<tr>
<td style="text-align:left;">
IICHMPUS
</td>
<td style="text-align:left;">
CHAMPUS - IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
IRPRVHLT
</td>
<td style="text-align:left;">
PRIVATE HEALTH INSURANCE - IMPUTATION REVISED
</td>
</tr>
<tr>
<td style="text-align:left;">
IIPRVHLT
</td>
<td style="text-align:left;">
PRIVATE HEALTH INSURANCE - IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
IROTHHLT
</td>
<td style="text-align:left;">
OTHER HEALTH INSURANCE - IMPUTATION REVISED
</td>
</tr>
<tr>
<td style="text-align:left;">
IIOTHHLT
</td>
<td style="text-align:left;">
OTHER HEALTH INSURANCE - IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
HLCALLFG
</td>
<td style="text-align:left;">
FLAG IF EVERY FORM OF HEALTH INS REPORTED
</td>
</tr>
<tr>
<td style="text-align:left;">
HLCALL99
</td>
<td style="text-align:left;">
YES TO MEDICARE/MEDICAID/CHAMPUS/PRVHLTIN
</td>
</tr>
<tr>
<td style="text-align:left;">
ANYHLTI2
</td>
<td style="text-align:left;">
COVERED BY ANY HEALTH INSURANCE - RECODE
</td>
</tr>
<tr>
<td style="text-align:left;">
IRINSUR4
</td>
<td style="text-align:left;">
RC-OVERALL HEALTH INSURANCE - IMPUTATION REVISED
</td>
</tr>
<tr>
<td style="text-align:left;">
IIINSUR4
</td>
<td style="text-align:left;">
RC-OVERALL HEALTH INSURANCE - IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
OTHINS
</td>
<td style="text-align:left;">
RC-OTHER HEALTH INSURANCE
</td>
</tr>
<tr>
<td style="text-align:left;">
CELLNOTCL
</td>
<td style="text-align:left;">
NOT A CELL PHONE
</td>
</tr>
<tr>
<td style="text-align:left;">
CELLWRKNG
</td>
<td style="text-align:left;">
WORKING CELL PHONE
</td>
</tr>
<tr>
<td style="text-align:left;">
IRFAMSOC
</td>
<td style="text-align:left;">
FAM RECEIVE SS OR RR PAYMENTS - IMPUTATION REVISED
</td>
</tr>
<tr>
<td style="text-align:left;">
IIFAMSOC
</td>
<td style="text-align:left;">
FAM RECEIVE SS OR RR PAYMENTS - IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
IRFAMSSI
</td>
<td style="text-align:left;">
FAM RECEIVE SSI - IMPUTATION REVISED
</td>
</tr>
<tr>
<td style="text-align:left;">
IIFAMSSI
</td>
<td style="text-align:left;">
FAM RECEIVE SSI - IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
IRFSTAMP
</td>
<td style="text-align:left;">
RESP/OTH FAM MEM REC FOOD STAMPS - IMPUTATION REVISED
</td>
</tr>
<tr>
<td style="text-align:left;">
IIFSTAMP
</td>
<td style="text-align:left;">
RESP/OTH FAM MEM REC FOOD STAMPS - IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
IRFAMPMT
</td>
<td style="text-align:left;">
FAM RECEIVE PUBLIC ASSIST - IMPUTATION REVISED
</td>
</tr>
<tr>
<td style="text-align:left;">
IIFAMPMT
</td>
<td style="text-align:left;">
FAM RECEIVE PUBLIC ASSIST - IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
IRFAMSVC
</td>
<td style="text-align:left;">
FAM REC WELFARE/JOB PL/CHILDCARE - IMPUTATION REVISED
</td>
</tr>
<tr>
<td style="text-align:left;">
IIFAMSVC
</td>
<td style="text-align:left;">
FAM REC WELFARE/JOB PL/CHILDCARE - IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
IRWELMOS
</td>
<td style="text-align:left;">
IMP. REVISED - NO.OF MONTHS ON WELFARE
</td>
</tr>
<tr>
<td style="text-align:left;">
IIWELMOS
</td>
<td style="text-align:left;">
NO OF MONTHS ON WELFARE - IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
IRPINC3
</td>
<td style="text-align:left;">
RESP TOT INCOME (FINER CAT) - IMP REV
</td>
</tr>
<tr>
<td style="text-align:left;">
IRFAMIN3
</td>
<td style="text-align:left;">
RECODE - IMP.REVISED - TOT FAM INCOME
</td>
</tr>
<tr>
<td style="text-align:left;">
IIPINC3
</td>
<td style="text-align:left;">
RESP TOT INCOME (FINER CAT) - IMP INDIC
</td>
</tr>
<tr>
<td style="text-align:left;">
IIFAMIN3
</td>
<td style="text-align:left;">
IRFAMIN3 - IMPUTATION INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
GOVTPROG
</td>
<td style="text-align:left;">
RC-PARTICIPATED IN ONE OR MORE GOVT ASSIST PROGRAMS
</td>
</tr>
<tr>
<td style="text-align:left;">
POVERTY3
</td>
<td style="text-align:left;">
RC-POVERTY LEVEL
</td>
</tr>
<tr>
<td style="text-align:left;">
TOOLONG
</td>
<td style="text-align:left;">
RESP SAID INTERVIEW WAS TOO LONG
</td>
</tr>
<tr>
<td style="text-align:left;">
TROUBUND
</td>
<td style="text-align:left;">
DID RESP HAVE TROUBLE UNDERSTANDING INTERVIEW
</td>
</tr>
<tr>
<td style="text-align:left;">
PDEN10
</td>
<td style="text-align:left;">
POPULATION DENSITY 2010
</td>
</tr>
<tr>
<td style="text-align:left;">
COUTYP2
</td>
<td style="text-align:left;">
COUNTY METRO/NONMETRO STATUS
</td>
</tr>
<tr>
<td style="text-align:left;">
MAIIN102
</td>
<td style="text-align:left;">
MAJORITY AMER INDIAN AREA INDICATOR FOR SEGMENT
</td>
</tr>
<tr>
<td style="text-align:left;">
AIIND102
</td>
<td style="text-align:left;">
AMER INDIAN AREA INDICATOR
</td>
</tr>
<tr>
<td style="text-align:left;">
ANALWT_C
</td>
<td style="text-align:left;">
FIN PRSN-LEVEL SIMPLE WGHT
</td>
</tr>
<tr>
<td style="text-align:left;">
VESTR
</td>
<td style="text-align:left;">
ANALYSIS STRATUM
</td>
</tr>
<tr>
<td style="text-align:left;">
VEREP
</td>
<td style="text-align:left;">
ANALYSIS REPLICATE
</td>
</tr>
<tr>
<td style="text-align:left;">
Criminal
</td>
<td style="text-align:left;">
Target Variable
</td>
</tr>
</tbody>
</table>
</div>
<div id="structure-of-data" class="section level2">
<h2>Structure of Data</h2>
<p>We’ll just take a quick look into the structure of the data for each of the variables. Obviously we see that the data is already encoded and has the data type <code>integer</code>. Even our target variable has its data type set to integer. We will require to change that to <code>factor</code> since we’ll be using the <strong>GBM</strong> model to classify our target variable into one of the two levels (<strong>1</strong> if person is criminal and <strong>0</strong> otherwise )</p>
<pre class="r"><code>train &lt;- read.csv(&quot;~/Desktop/ME/MyWebsites/Blog2/data/Criminal/Data/criminal_train.csv&quot;)
str(train)</code></pre>
<pre><code>## &#39;data.frame&#39;:    45718 obs. of  72 variables:
##  $ PERID    : int  25095143 13005143 67415143 70925143 75235143 47745143 33145143 63765143 57796143 66416143 ...
##  $ IFATHER  : int  4 4 4 4 1 4 4 4 4 4 ...
##  $ NRCH17_2 : int  2 1 1 0 0 0 3 2 1 0 ...
##  $ IRHHSIZ2 : int  4 3 2 2 6 2 6 4 3 1 ...
##  $ IIHHSIZ2 : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ IRKI17_2 : int  3 2 2 1 4 1 4 3 2 1 ...
##  $ IIKI17_2 : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ IRHH65_2 : int  1 1 1 1 1 1 1 1 1 2 ...
##  $ IIHH65_2 : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ PRXRETRY : int  99 99 99 99 99 99 99 99 99 99 ...
##  $ PRXYDATA : int  99 99 99 99 1 99 99 99 99 99 ...
##  $ MEDICARE : int  2 2 2 2 2 2 2 2 2 1 ...
##  $ CAIDCHIP : int  1 2 1 2 1 2 1 2 2 2 ...
##  $ CHAMPUS  : int  2 2 2 2 2 2 2 2 2 2 ...
##  $ PRVHLTIN : int  2 1 2 1 2 2 2 2 2 1 ...
##  $ GRPHLTIN : int  99 1 99 1 99 99 99 99 99 1 ...
##  $ HLTINNOS : int  99 99 99 99 99 2 99 2 2 99 ...
##  $ HLCNOTYR : int  2 2 2 2 2 99 2 99 99 2 ...
##  $ HLCNOTMO : int  99 99 99 99 99 99 99 99 99 99 ...
##  $ HLCLAST  : int  99 99 99 99 99 1 99 5 2 99 ...
##  $ HLLOSRSN : int  99 99 99 99 99 1 99 99 2 99 ...
##  $ HLNVCOST : int  99 99 99 99 99 99 99 1 99 99 ...
##  $ HLNVOFFR : int  99 99 99 99 99 99 99 6 99 99 ...
##  $ HLNVREF  : int  99 99 99 99 99 99 99 6 99 99 ...
##  $ HLNVNEED : int  99 99 99 99 99 99 99 6 99 99 ...
##  $ HLNVSOR  : int  99 99 99 99 99 99 99 6 99 99 ...
##  $ IRMCDCHP : int  1 2 1 2 1 2 1 2 2 2 ...
##  $ IIMCDCHP : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ IRMEDICR : int  2 2 2 2 2 2 2 2 2 1 ...
##  $ IIMEDICR : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ IRCHMPUS : int  2 2 2 2 2 2 2 2 2 2 ...
##  $ IICHMPUS : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ IRPRVHLT : int  2 1 2 1 2 2 2 2 2 1 ...
##  $ IIPRVHLT : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ IROTHHLT : int  99 99 99 99 99 2 99 2 2 99 ...
##  $ IIOTHHLT : int  9 9 9 9 9 1 9 1 1 9 ...
##  $ HLCALLFG : int  98 98 98 98 98 98 98 98 98 98 ...
##  $ HLCALL99 : int  98 98 98 98 98 98 98 98 98 98 ...
##  $ ANYHLTI2 : int  1 1 1 1 1 2 1 2 2 1 ...
##  $ IRINSUR4 : int  1 1 1 1 1 2 1 2 2 1 ...
##  $ IIINSUR4 : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ OTHINS   : int  2 2 2 2 2 2 2 2 2 1 ...
##  $ CELLNOTCL: int  1 1 2 1 2 2 2 1 2 1 ...
##  $ CELLWRKNG: int  1 1 1 1 1 1 1 1 1 1 ...
##  $ IRFAMSOC : int  2 2 1 2 2 2 2 2 2 1 ...
##  $ IIFAMSOC : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ IRFAMSSI : int  2 2 2 2 2 2 2 2 2 2 ...
##  $ IIFAMSSI : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ IRFSTAMP : int  1 1 1 2 1 2 1 1 2 2 ...
##  $ IIFSTAMP : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ IRFAMPMT : int  2 2 2 2 2 2 1 2 2 2 ...
##  $ IIFAMPMT : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ IRFAMSVC : int  2 2 2 2 1 2 2 2 2 2 ...
##  $ IIFAMSVC : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ IRWELMOS : int  99 99 99 99 1 99 1 99 99 99 ...
##  $ IIWELMOS : int  9 9 9 9 1 9 1 9 9 9 ...
##  $ IRPINC3  : int  1 1 2 7 1 2 1 1 1 6 ...
##  $ IRFAMIN3 : int  4 1 2 7 2 3 1 1 1 6 ...
##  $ IIPINC3  : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ IIFAMIN3 : int  1 1 1 1 1 1 1 1 3 1 ...
##  $ GOVTPROG : int  1 1 1 2 1 2 1 1 2 2 ...
##  $ POVERTY3 : int  2 1 1 3 1 2 1 1 1 3 ...
##  $ TOOLONG  : int  1 2 2 2 2 2 2 2 2 2 ...
##  $ TROUBUND : int  2 2 2 2 2 2 2 2 2 2 ...
##  $ PDEN10   : int  1 2 2 1 2 2 2 2 2 1 ...
##  $ COUTYP2  : int  1 3 3 1 2 3 2 2 1 1 ...
##  $ MAIIN102 : int  2 2 2 2 2 2 2 2 2 2 ...
##  $ AIIND102 : int  2 2 2 2 2 2 2 2 2 2 ...
##  $ ANALWT_C : num  3885 1627 4345 793 1518 ...
##  $ VESTR    : int  40026 40015 40024 40027 40001 40035 40043 40006 40021 40006 ...
##  $ VEREP    : int  1 2 1 1 2 2 2 2 2 1 ...
##  $ Criminal : int  0 1 0 0 0 0 0 0 0 0 ...</code></pre>
</div>
</div>
<div id="a-summary-of-dataset." class="section level1">
<h1>A summary of dataset.</h1>
<p>Lets quickly get a headcount of what is the ratio of criminals in our dataset.</p>
<pre class="r"><code>train %&gt;% group_by(Criminal) %&gt;% summarise(Count=length(Criminal)) %&gt;% 
  kable(format = &quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;,&quot;hover&quot;,&quot;condensed&quot;))</code></pre>
<table class="table table-striped table-hover table-condensed" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
Criminal
</th>
<th style="text-align:right;">
Count
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
42543
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
3175
</td>
</tr>
</tbody>
</table>
<p>That is 1 in every 3545.</p>
<div id="preparing-data." class="section level2">
<h2>Preparing Data.</h2>
<p>We’ll identify our target varible and our predictor variables by giving them seperate names. This will help in reproducing the below code for a different set of predictors and target without having to change our code by much.</p>
<pre class="r"><code>outcomeVariable &lt;- &quot;Criminal&quot;
predictorVariables &lt;- colnames(train)[colnames(train) != outcomeVariable]</code></pre>
<p>Since our problem is of the type <strong>“Classification”</strong>, we’ll have to turn our target variables into type <em>factor</em> instead of <em>integer</em></p>
<pre class="r"><code>train[,outcomeVariable] &lt;- ifelse(train[,outcomeVariable]==1,&#39;yes&#39;,&#39;nope&#39;)
train[,outcomeVariable] &lt;- as.factor(train[,outcomeVariable])</code></pre>
</div>
</div>
<div id="developing-a-model" class="section level1 tabset tabset-fade tabset-pills">
<h1>Developing a model</h1>
<div id="splitting-the-train-data." class="section level2">
<h2>Splitting the train data.</h2>
<p>Next we have to split the training data into 2 partitions. The first partition- <code>trainDF</code> will be used to train our model and later on we can then test the performance of the model on the second partition - <code>testDF</code> which will give us a pretty good idea about how accurate our model is.</p>
<pre class="r"><code>set.seed(1234)
splitIndex &lt;- createDataPartition(train[,outcomeVariable], p = .75, list = FALSE, times = 1)
trainDF &lt;- train[ splitIndex,]
testDF  &lt;- train[-splitIndex,]</code></pre>
</div>
<div id="choosing-parameters-gbm" class="section level2">
<h2>Choosing parameters (GBM)</h2>
<p>The GBM model takes into account 3 important parameters.</p>
<ul>
<li><code>trees</code></li>
<li><code>shrinkage</code></li>
<li><code>interaction depth</code></li>
</ul>
<p>we can pass the values to these parameters manually or we can make use of the <code>trainControl</code> function which will choose the best values of these parameters. Over here, we’re going to do just that.</p>
<pre class="r"><code>objControl &lt;- trainControl(method=&#39;cv&#39;, number=3, returnResamp=&#39;none&#39;, summaryFunction = twoClassSummary, classProbs = TRUE)</code></pre>
</div>
<div id="gbm-model" class="section level2">
<h2>GBM Model</h2>
<p>Now that our parameters are set, we can now create a model.</p>
<pre class="r"><code>objModel &lt;- train(trainDF[,predictorVariables], trainDF[,outcomeVariable], 
                  method=&#39;gbm&#39;, 
                  trControl=objControl,  
                  metric = &quot;ROC&quot;,
                  preProc = c(&quot;center&quot;, &quot;scale&quot;))</code></pre>
<pre><code>## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4918            -nan     0.1000    0.0064
##      2        0.4817            -nan     0.1000    0.0052
##      3        0.4717            -nan     0.1000    0.0052
##      4        0.4621            -nan     0.1000    0.0047
##      5        0.4525            -nan     0.1000    0.0047
##      6        0.4439            -nan     0.1000    0.0042
##      7        0.4353            -nan     0.1000    0.0042
##      8        0.4277            -nan     0.1000    0.0038
##      9        0.4205            -nan     0.1000    0.0038
##     10        0.4135            -nan     0.1000    0.0035
##     20        0.3590            -nan     0.1000    0.0021
##     40        0.3050            -nan     0.1000    0.0008
##     60        0.2765            -nan     0.1000    0.0004
##     80        0.2554            -nan     0.1000    0.0001
##    100        0.2422            -nan     0.1000   -0.0000
##    120        0.2348            -nan     0.1000   -0.0000
##    140        0.2292            -nan     0.1000   -0.0000
##    150        0.2271            -nan     0.1000    0.0003
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4536            -nan     0.1000    0.0252
##      2        0.4204            -nan     0.1000    0.0160
##      3        0.3971            -nan     0.1000    0.0116
##      4        0.3788            -nan     0.1000    0.0089
##      5        0.3647            -nan     0.1000    0.0072
##      6        0.3523            -nan     0.1000    0.0059
##      7        0.3425            -nan     0.1000    0.0049
##      8        0.3376            -nan     0.1000    0.0024
##      9        0.3294            -nan     0.1000    0.0041
##     10        0.3221            -nan     0.1000    0.0035
##     20        0.2803            -nan     0.1000    0.0019
##     40        0.2376            -nan     0.1000    0.0010
##     60        0.2240            -nan     0.1000   -0.0000
##     80        0.2176            -nan     0.1000   -0.0000
##    100        0.2135            -nan     0.1000    0.0001
##    120        0.2112            -nan     0.1000   -0.0000
##    140        0.2094            -nan     0.1000    0.0000
##    150        0.2088            -nan     0.1000   -0.0000
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4356            -nan     0.1000    0.0330
##      2        0.4023            -nan     0.1000    0.0165
##      3        0.3752            -nan     0.1000    0.0134
##      4        0.3491            -nan     0.1000    0.0125
##      5        0.3319            -nan     0.1000    0.0084
##      6        0.3180            -nan     0.1000    0.0067
##      7        0.3049            -nan     0.1000    0.0064
##      8        0.2947            -nan     0.1000    0.0051
##      9        0.2861            -nan     0.1000    0.0042
##     10        0.2783            -nan     0.1000    0.0039
##     20        0.2468            -nan     0.1000    0.0008
##     40        0.2211            -nan     0.1000    0.0002
##     60        0.2139            -nan     0.1000    0.0001
##     80        0.2102            -nan     0.1000   -0.0001
##    100        0.2080            -nan     0.1000    0.0001
##    120        0.2059            -nan     0.1000   -0.0000
##    140        0.2035            -nan     0.1000   -0.0000
##    150        0.2027            -nan     0.1000   -0.0001
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4919            -nan     0.1000    0.0063
##      2        0.4815            -nan     0.1000    0.0052
##      3        0.4705            -nan     0.1000    0.0051
##      4        0.4609            -nan     0.1000    0.0047
##      5        0.4514            -nan     0.1000    0.0046
##      6        0.4434            -nan     0.1000    0.0042
##      7        0.4352            -nan     0.1000    0.0041
##      8        0.4273            -nan     0.1000    0.0038
##      9        0.4203            -nan     0.1000    0.0037
##     10        0.4134            -nan     0.1000    0.0035
##     20        0.3602            -nan     0.1000    0.0023
##     40        0.3077            -nan     0.1000    0.0008
##     60        0.2725            -nan     0.1000    0.0003
##     80        0.2522            -nan     0.1000    0.0003
##    100        0.2391            -nan     0.1000    0.0002
##    120        0.2312            -nan     0.1000    0.0001
##    140        0.2244            -nan     0.1000    0.0000
##    150        0.2228            -nan     0.1000   -0.0000
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4536            -nan     0.1000    0.0251
##      2        0.4223            -nan     0.1000    0.0162
##      3        0.3986            -nan     0.1000    0.0119
##      4        0.3805            -nan     0.1000    0.0092
##      5        0.3656            -nan     0.1000    0.0073
##      6        0.3533            -nan     0.1000    0.0060
##      7        0.3472            -nan     0.1000    0.0027
##      8        0.3376            -nan     0.1000    0.0049
##      9        0.3296            -nan     0.1000    0.0037
##     10        0.3233            -nan     0.1000    0.0030
##     20        0.2763            -nan     0.1000    0.0002
##     40        0.2353            -nan     0.1000    0.0006
##     60        0.2195            -nan     0.1000    0.0001
##     80        0.2130            -nan     0.1000   -0.0000
##    100        0.2095            -nan     0.1000   -0.0000
##    120        0.2077            -nan     0.1000   -0.0001
##    140        0.2056            -nan     0.1000    0.0001
##    150        0.2048            -nan     0.1000   -0.0000
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4348            -nan     0.1000    0.0349
##      2        0.3975            -nan     0.1000    0.0184
##      3        0.3665            -nan     0.1000    0.0154
##      4        0.3466            -nan     0.1000    0.0095
##      5        0.3305            -nan     0.1000    0.0078
##      6        0.3155            -nan     0.1000    0.0076
##      7        0.3036            -nan     0.1000    0.0061
##      8        0.2983            -nan     0.1000    0.0024
##      9        0.2884            -nan     0.1000    0.0049
##     10        0.2801            -nan     0.1000    0.0041
##     20        0.2428            -nan     0.1000    0.0005
##     40        0.2176            -nan     0.1000    0.0001
##     60        0.2093            -nan     0.1000    0.0002
##     80        0.2059            -nan     0.1000   -0.0001
##    100        0.2034            -nan     0.1000   -0.0001
##    120        0.2012            -nan     0.1000   -0.0000
##    140        0.1992            -nan     0.1000    0.0000
##    150        0.1984            -nan     0.1000   -0.0001
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4913            -nan     0.1000    0.0065
##      2        0.4806            -nan     0.1000    0.0053
##      3        0.4704            -nan     0.1000    0.0051
##      4        0.4609            -nan     0.1000    0.0048
##      5        0.4515            -nan     0.1000    0.0046
##      6        0.4433            -nan     0.1000    0.0043
##      7        0.4351            -nan     0.1000    0.0041
##      8        0.4276            -nan     0.1000    0.0039
##      9        0.4203            -nan     0.1000    0.0037
##     10        0.4132            -nan     0.1000    0.0036
##     20        0.3590            -nan     0.1000    0.0023
##     40        0.3039            -nan     0.1000    0.0014
##     60        0.2721            -nan     0.1000    0.0009
##     80        0.2524            -nan     0.1000    0.0007
##    100        0.2398            -nan     0.1000    0.0001
##    120        0.2306            -nan     0.1000    0.0001
##    140        0.2249            -nan     0.1000    0.0000
##    150        0.2228            -nan     0.1000    0.0001
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4539            -nan     0.1000    0.0255
##      2        0.4217            -nan     0.1000    0.0163
##      3        0.3978            -nan     0.1000    0.0118
##      4        0.3796            -nan     0.1000    0.0091
##      5        0.3648            -nan     0.1000    0.0073
##      6        0.3527            -nan     0.1000    0.0060
##      7        0.3425            -nan     0.1000    0.0050
##      8        0.3351            -nan     0.1000    0.0038
##      9        0.3264            -nan     0.1000    0.0042
##     10        0.3220            -nan     0.1000    0.0023
##     20        0.2762            -nan     0.1000    0.0022
##     40        0.2342            -nan     0.1000    0.0002
##     60        0.2196            -nan     0.1000    0.0005
##     80        0.2144            -nan     0.1000   -0.0000
##    100        0.2100            -nan     0.1000   -0.0000
##    120        0.2077            -nan     0.1000    0.0000
##    140        0.2057            -nan     0.1000   -0.0000
##    150        0.2044            -nan     0.1000   -0.0000
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4366            -nan     0.1000    0.0346
##      2        0.3995            -nan     0.1000    0.0184
##      3        0.3669            -nan     0.1000    0.0157
##      4        0.3474            -nan     0.1000    0.0095
##      5        0.3297            -nan     0.1000    0.0088
##      6        0.3149            -nan     0.1000    0.0071
##      7        0.3095            -nan     0.1000    0.0025
##      8        0.2989            -nan     0.1000    0.0055
##      9        0.2888            -nan     0.1000    0.0049
##     10        0.2811            -nan     0.1000    0.0038
##     20        0.2416            -nan     0.1000    0.0018
##     40        0.2176            -nan     0.1000    0.0006
##     60        0.2092            -nan     0.1000    0.0001
##     80        0.2064            -nan     0.1000   -0.0000
##    100        0.2030            -nan     0.1000   -0.0001
##    120        0.2014            -nan     0.1000   -0.0001
##    140        0.1996            -nan     0.1000   -0.0001
##    150        0.1988            -nan     0.1000   -0.0000
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4371            -nan     0.1000    0.0338
##      2        0.3961            -nan     0.1000    0.0201
##      3        0.3702            -nan     0.1000    0.0129
##      4        0.3475            -nan     0.1000    0.0113
##      5        0.3303            -nan     0.1000    0.0085
##      6        0.3164            -nan     0.1000    0.0069
##      7        0.3034            -nan     0.1000    0.0063
##      8        0.2934            -nan     0.1000    0.0049
##      9        0.2890            -nan     0.1000    0.0019
##     10        0.2806            -nan     0.1000    0.0041
##     20        0.2437            -nan     0.1000    0.0004
##     40        0.2190            -nan     0.1000    0.0002
##     60        0.2123            -nan     0.1000   -0.0000
##     80        0.2090            -nan     0.1000   -0.0000
##    100        0.2065            -nan     0.1000   -0.0000
##    120        0.2047            -nan     0.1000   -0.0000
##    140        0.2038            -nan     0.1000   -0.0001
##    150        0.2031            -nan     0.1000   -0.0001</code></pre>
<p>After creating a model, lets have a quick look at the variables and their relative influence on our output variable</p>
<pre class="r"><code>summary(objModel)</code></pre>
<p><img src="/post/2018-02-05-predict-the-criminals_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre><code>##                 var      rel.inf
## GRPHLTIN   GRPHLTIN 43.674482136
## IRFAMIN3   IRFAMIN3 20.733352266
## IRPINC3     IRPINC3 11.057674945
## IFATHER     IFATHER  9.588943601
## IRMEDICR   IRMEDICR  7.689551281
## IRPRVHLT   IRPRVHLT  1.372119187
## POVERTY3   POVERTY3  1.017095075
## ANALWT_C   ANALWT_C  0.793418038
## PRVHLTIN   PRVHLTIN  0.639839025
## PERID         PERID  0.635383244
## CELLNOTCL CELLNOTCL  0.378938502
## IRFAMSOC   IRFAMSOC  0.349041147
## PRXYDATA   PRXYDATA  0.291052221
## MEDICARE   MEDICARE  0.277736643
## IRHHSIZ2   IRHHSIZ2  0.190436223
## VESTR         VESTR  0.177281884
## HLCNOTMO   HLCNOTMO  0.106181878
## IIFAMSSI   IIFAMSSI  0.084817013
## PDEN10       PDEN10  0.080050274
## NRCH17_2   NRCH17_2  0.074040915
## CAIDCHIP   CAIDCHIP  0.072778202
## IIWELMOS   IIWELMOS  0.071822488
## VEREP         VEREP  0.064524688
## CELLWRKNG CELLWRKNG  0.059871927
## ANYHLTI2   ANYHLTI2  0.051383720
## GOVTPROG   GOVTPROG  0.046990713
## CHAMPUS     CHAMPUS  0.044893595
## COUTYP2     COUTYP2  0.040762944
## IRHH65_2   IRHH65_2  0.036501967
## HLCNOTYR   HLCNOTYR  0.034450145
## PRXRETRY   PRXRETRY  0.033912281
## IRKI17_2   IRKI17_2  0.029253668
## TROUBUND   TROUBUND  0.027241688
## IIFAMSVC   IIFAMSVC  0.025122167
## IIFAMIN3   IIFAMIN3  0.024965428
## IIFAMSOC   IIFAMSOC  0.019951893
## TOOLONG     TOOLONG  0.018547615
## IIHH65_2   IIHH65_2  0.017405200
## IIFAMPMT   IIFAMPMT  0.016519325
## IRFAMSSI   IRFAMSSI  0.016494230
## IIFSTAMP   IIFSTAMP  0.013162846
## IIKI17_2   IIKI17_2  0.008330601
## IIPINC3     IIPINC3  0.007346404
## IRMCDCHP   IRMCDCHP  0.006330768
## IIHHSIZ2   IIHHSIZ2  0.000000000
## HLTINNOS   HLTINNOS  0.000000000
## HLCLAST     HLCLAST  0.000000000
## HLLOSRSN   HLLOSRSN  0.000000000
## HLNVCOST   HLNVCOST  0.000000000
## HLNVOFFR   HLNVOFFR  0.000000000
## HLNVREF     HLNVREF  0.000000000
## HLNVNEED   HLNVNEED  0.000000000
## HLNVSOR     HLNVSOR  0.000000000
## IIMCDCHP   IIMCDCHP  0.000000000
## IIMEDICR   IIMEDICR  0.000000000
## IRCHMPUS   IRCHMPUS  0.000000000
## IICHMPUS   IICHMPUS  0.000000000
## IIPRVHLT   IIPRVHLT  0.000000000
## IROTHHLT   IROTHHLT  0.000000000
## IIOTHHLT   IIOTHHLT  0.000000000
## HLCALLFG   HLCALLFG  0.000000000
## HLCALL99   HLCALL99  0.000000000
## IRINSUR4   IRINSUR4  0.000000000
## IIINSUR4   IIINSUR4  0.000000000
## OTHINS       OTHINS  0.000000000
## IRFSTAMP   IRFSTAMP  0.000000000
## IRFAMPMT   IRFAMPMT  0.000000000
## IRFAMSVC   IRFAMSVC  0.000000000
## IRWELMOS   IRWELMOS  0.000000000
## MAIIN102   MAIIN102  0.000000000
## AIIND102   AIIND102  0.000000000</code></pre>
<p>We find that the</p>
<ol style="list-style-type: decimal">
<li><code>GRPHLTIN</code> <em>( PRIVATE PLAN OFFERED THROUGH EMPLOYER OR UNION )</em></li>
<li><code>IRFAMIN3</code> <em>(RECODE - IMP.REVISED - TOT FAM INCOME)</em></li>
<li><code>IRPINC3</code> <em>(RESP TOT INCOME (FINER CAT) - IMP REV )</em></li>
<li><code>IFATHER</code> <em>( FATHER IN HOUSEHOLD )</em></li>
<li><code>IRMEDICR</code> <em>(MEDICARE - IMPUTATION REVISED)</em></li>
</ol>
<p>Now this is interesting but at the same time it is also what we would have expected. An individuals income and consequences of living in a household without a father figure are a few of the variables we could have expected to contribute significantly.</p>
<p>Also lets take a look at what tuning parameters were used.</p>
<pre class="r"><code>print(objModel)</code></pre>
<pre><code>## Stochastic Gradient Boosting 
## 
## 34290 samples
##    71 predictor
##     2 classes: &#39;nope&#39;, &#39;yes&#39; 
## 
## Pre-processing: centered (71), scaled (71) 
## Resampling: Cross-Validated (3 fold) 
## Summary of sample sizes: 22860, 22860, 22860 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  ROC        Sens       Spec       
##   1                   50      0.9678422  0.9998120  0.003358522
##   1                  100      0.9702975  0.9955184  0.145675903
##   1                  150      0.9705528  0.9846747  0.497481108
##   2                   50      0.9704918  0.9842986  0.505877414
##   2                  100      0.9712187  0.9824182  0.555835432
##   2                  150      0.9711431  0.9823555  0.558354324
##   3                   50      0.9708925  0.9826689  0.557094878
##   3                  100      0.9711643  0.9821675  0.557934509
##   3                  150      0.9713693  0.9819794  0.561293031
## 
## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1
## 
## Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value of 10
## ROC was used to select the optimal model using  the largest value.
## The final values used for the model were n.trees = 150,
##  interaction.depth = 3, shrinkage = 0.1 and n.minobsinnode = 10.</code></pre>
</div>
</div>
<div id="evaluate-model" class="section level1">
<h1>Evaluate Model</h1>
<p>In order to check how good our model is performing, we’ll use it to predict it on our <code>testDF</code> of which we already know the values of the target variable.</p>
<pre class="r"><code>predictions &lt;- predict(object = objModel,testDF[,predictorVariables],type = &quot;raw&quot;)
head(predictions)</code></pre>
<pre><code>## [1] nope nope nope nope nope nope
## Levels: nope yes</code></pre>
<p>Now lets get our accuracy score. <code>postResample</code> function in the <code>caret</code> library provides us with an easy way to compare results.</p>
<pre class="r"><code>print(postResample(pred=predictions, obs=as.factor(testDF[,outcomeVariable])))</code></pre>
<pre><code>##  Accuracy     Kappa 
## 0.9524851 0.5923798</code></pre>
<p>That’s an accuracy of above 95%.</p>
</div>
<div id="predicting-output" class="section level1">
<h1>Predicting Output</h1>
<p>We’ll now import the test files</p>
<pre class="r"><code>test_Y &lt;- read.csv(&quot;~/Desktop/ME/MyWebsites/Blog2/data/Criminal/Data/criminal_test.csv&quot;)</code></pre>
<p>lets start predicting the output.</p>
<pre class="r"><code>predictions_output &lt;- predict(object = objModel,test_Y[,predictorVariables],type = &quot;raw&quot;)
predictions_output &lt;- as.data.frame(predictions_output)</code></pre>
<div id="creating-final-dataframe-for-submission" class="section level2">
<h2>Creating final dataframe for submission</h2>
<pre class="r"><code>Submission &lt;- bind_cols(PERID=test_Y$PERID,Criminal=predictions_output)
colnames(Submission) &lt;- c(&quot;PERID&quot;,&quot;Criminal&quot;)
Submission$Criminal &lt;- ifelse(Submission$Criminal==&quot;nope&quot;,0,1)

write.csv(Submission,&quot;Submission.csv&quot;,row.names = FALSE)</code></pre>
</div>
</div>
