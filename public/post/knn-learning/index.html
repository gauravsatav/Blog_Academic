<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.31" />
  <meta name="author" content="Gaurav Satav">
  <meta name="description" content="Data Scientist">

  
  <link rel="alternate" hreflang="en-us" href="../../post/knn-learning/">

  
  


  

  
  
  
  
    
  
  
    
    
      
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
      
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Playfair&#43;Display:400,700%7cFauna&#43;One">
  
  <link rel="stylesheet" href="../../styles.css">
  

  

  
  <link rel="alternate" href="../../index.xml" type="application/rss+xml" title="GAURAV SATAV">
  <link rel="feed" href="../../index.xml" type="application/rss+xml" title="GAURAV SATAV">
  

  <link rel="manifest" href="../../site.webmanifest">
  <link rel="icon" type="image/png" href="../../img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="../../img/icon-192.png">

  <link rel="canonical" href="../../post/knn-learning/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="GAURAV SATAV">
  <meta property="og:url" content="/post/knn-learning/">
  <meta property="og:title" content="KNN Learning | GAURAV SATAV">
  <meta property="og:description" content="">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2017-12-04T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2017-12-04T00:00:00&#43;00:00">
  

  

  <title>KNN Learning | GAURAV SATAV</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="../../">GAURAV SATAV</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        

        
          
        

        <li class="nav-item">
          <a href="../../#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="../../#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="../../#about">
            
            <span>About</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="../../#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <div class="article-inner">
      <h1 itemprop="name">KNN Learning</h1>

      

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2017-12-04 00:00:00 &#43;0000 UTC" itemprop="datePublished">
      Dec 4, 2017
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    10 min read
  </span>
  

  
  
  <span class="middot-divider"></span>
  <a href="../../post/knn-learning/#disqus_thread"></a>
  

  
  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fa fa-folder"></i>
    
    <a href="../../categories/r">R</a
    >, 
    
    <a href="../../categories/machinelearning">machinelearning</a
    >
    
  </span>
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=KNN%20Learning&amp;url=%2fpost%2fknn-learning%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2fknn-learning%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2fknn-learning%2f&amp;title=KNN%20Learning"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2fknn-learning%2f&amp;title=KNN%20Learning"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=KNN%20Learning&amp;body=%2fpost%2fknn-learning%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


      <div class="article-style" itemprop="articleBody">
        <div id="installing-required-packages." class="section level2">
<h2>INSTALLING REQUIRED PACKAGES.</h2>
<pre class="r"><code>library(class)
library(caret)
require(mlbench)
library(e1071)
library(base)
require(base)
library(kableExtra)
library(knitr)</code></pre>
</div>
<div id="step-1--data-collection" class="section level2">
<h2>Step 1- Data collection</h2>
<p>For this lesson, we will be using Sonar data set (signals) from mlbench library. Sonar is a system for the detection of objects under water and for measuring the water’s depth by emitting sound pulses and detecting. The complete description can be found in mlbench. For our purposes, this is a two-class (class R and class M) classification task with numeric data.</p>
<p>Let’s look at the first five rows of Sonar</p>
<div style="border: 1px solid #ddd; padding: 5px; overflow-x: scroll; width:750px; ">
<table class="table table-hover" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
V1
</th>
<th style="text-align:right;">
V2
</th>
<th style="text-align:right;">
V3
</th>
<th style="text-align:right;">
V4
</th>
<th style="text-align:right;">
V5
</th>
<th style="text-align:right;">
V6
</th>
<th style="text-align:right;">
V7
</th>
<th style="text-align:right;">
V8
</th>
<th style="text-align:right;">
V9
</th>
<th style="text-align:right;">
V10
</th>
<th style="text-align:right;">
V11
</th>
<th style="text-align:right;">
V12
</th>
<th style="text-align:right;">
V13
</th>
<th style="text-align:right;">
V14
</th>
<th style="text-align:right;">
V15
</th>
<th style="text-align:right;">
V16
</th>
<th style="text-align:right;">
V17
</th>
<th style="text-align:right;">
V18
</th>
<th style="text-align:right;">
V19
</th>
<th style="text-align:right;">
V20
</th>
<th style="text-align:right;">
V21
</th>
<th style="text-align:right;">
V22
</th>
<th style="text-align:right;">
V23
</th>
<th style="text-align:right;">
V24
</th>
<th style="text-align:right;">
V25
</th>
<th style="text-align:right;">
V26
</th>
<th style="text-align:right;">
V27
</th>
<th style="text-align:right;">
V28
</th>
<th style="text-align:right;">
V29
</th>
<th style="text-align:right;">
V30
</th>
<th style="text-align:right;">
V31
</th>
<th style="text-align:right;">
V32
</th>
<th style="text-align:right;">
V33
</th>
<th style="text-align:right;">
V34
</th>
<th style="text-align:right;">
V35
</th>
<th style="text-align:right;">
V36
</th>
<th style="text-align:right;">
V37
</th>
<th style="text-align:right;">
V38
</th>
<th style="text-align:right;">
V39
</th>
<th style="text-align:right;">
V40
</th>
<th style="text-align:right;">
V41
</th>
<th style="text-align:right;">
V42
</th>
<th style="text-align:right;">
V43
</th>
<th style="text-align:right;">
V44
</th>
<th style="text-align:right;">
V45
</th>
<th style="text-align:right;">
V46
</th>
<th style="text-align:right;">
V47
</th>
<th style="text-align:right;">
V48
</th>
<th style="text-align:right;">
V49
</th>
<th style="text-align:right;">
V50
</th>
<th style="text-align:right;">
V51
</th>
<th style="text-align:right;">
V52
</th>
<th style="text-align:right;">
V53
</th>
<th style="text-align:right;">
V54
</th>
<th style="text-align:right;">
V55
</th>
<th style="text-align:right;">
V56
</th>
<th style="text-align:right;">
V57
</th>
<th style="text-align:right;">
V58
</th>
<th style="text-align:right;">
V59
</th>
<th style="text-align:right;">
V60
</th>
<th style="text-align:left;">
Class
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.0200
</td>
<td style="text-align:right;">
0.0371
</td>
<td style="text-align:right;">
0.0428
</td>
<td style="text-align:right;">
0.0207
</td>
<td style="text-align:right;">
0.0954
</td>
<td style="text-align:right;">
0.0986
</td>
<td style="text-align:right;">
0.1539
</td>
<td style="text-align:right;">
0.1601
</td>
<td style="text-align:right;">
0.3109
</td>
<td style="text-align:right;">
0.2111
</td>
<td style="text-align:right;">
0.1609
</td>
<td style="text-align:right;">
0.1582
</td>
<td style="text-align:right;">
0.2238
</td>
<td style="text-align:right;">
0.0645
</td>
<td style="text-align:right;">
0.0660
</td>
<td style="text-align:right;">
0.2273
</td>
<td style="text-align:right;">
0.3100
</td>
<td style="text-align:right;">
0.2999
</td>
<td style="text-align:right;">
0.5078
</td>
<td style="text-align:right;">
0.4797
</td>
<td style="text-align:right;">
0.5783
</td>
<td style="text-align:right;">
0.5071
</td>
<td style="text-align:right;">
0.4328
</td>
<td style="text-align:right;">
0.5550
</td>
<td style="text-align:right;">
0.6711
</td>
<td style="text-align:right;">
0.6415
</td>
<td style="text-align:right;">
0.7104
</td>
<td style="text-align:right;">
0.8080
</td>
<td style="text-align:right;">
0.6791
</td>
<td style="text-align:right;">
0.3857
</td>
<td style="text-align:right;">
0.1307
</td>
<td style="text-align:right;">
0.2604
</td>
<td style="text-align:right;">
0.5121
</td>
<td style="text-align:right;">
0.7547
</td>
<td style="text-align:right;">
0.8537
</td>
<td style="text-align:right;">
0.8507
</td>
<td style="text-align:right;">
0.6692
</td>
<td style="text-align:right;">
0.6097
</td>
<td style="text-align:right;">
0.4943
</td>
<td style="text-align:right;">
0.2744
</td>
<td style="text-align:right;">
0.0510
</td>
<td style="text-align:right;">
0.2834
</td>
<td style="text-align:right;">
0.2825
</td>
<td style="text-align:right;">
0.4256
</td>
<td style="text-align:right;">
0.2641
</td>
<td style="text-align:right;">
0.1386
</td>
<td style="text-align:right;">
0.1051
</td>
<td style="text-align:right;">
0.1343
</td>
<td style="text-align:right;">
0.0383
</td>
<td style="text-align:right;">
0.0324
</td>
<td style="text-align:right;">
0.0232
</td>
<td style="text-align:right;">
0.0027
</td>
<td style="text-align:right;">
0.0065
</td>
<td style="text-align:right;">
0.0159
</td>
<td style="text-align:right;">
0.0072
</td>
<td style="text-align:right;">
0.0167
</td>
<td style="text-align:right;">
0.0180
</td>
<td style="text-align:right;">
0.0084
</td>
<td style="text-align:right;">
0.0090
</td>
<td style="text-align:right;">
0.0032
</td>
<td style="text-align:left;">
R
</td>
</tr>
<tr>
<td style="text-align:right;">
0.0453
</td>
<td style="text-align:right;">
0.0523
</td>
<td style="text-align:right;">
0.0843
</td>
<td style="text-align:right;">
0.0689
</td>
<td style="text-align:right;">
0.1183
</td>
<td style="text-align:right;">
0.2583
</td>
<td style="text-align:right;">
0.2156
</td>
<td style="text-align:right;">
0.3481
</td>
<td style="text-align:right;">
0.3337
</td>
<td style="text-align:right;">
0.2872
</td>
<td style="text-align:right;">
0.4918
</td>
<td style="text-align:right;">
0.6552
</td>
<td style="text-align:right;">
0.6919
</td>
<td style="text-align:right;">
0.7797
</td>
<td style="text-align:right;">
0.7464
</td>
<td style="text-align:right;">
0.9444
</td>
<td style="text-align:right;">
1.0000
</td>
<td style="text-align:right;">
0.8874
</td>
<td style="text-align:right;">
0.8024
</td>
<td style="text-align:right;">
0.7818
</td>
<td style="text-align:right;">
0.5212
</td>
<td style="text-align:right;">
0.4052
</td>
<td style="text-align:right;">
0.3957
</td>
<td style="text-align:right;">
0.3914
</td>
<td style="text-align:right;">
0.3250
</td>
<td style="text-align:right;">
0.3200
</td>
<td style="text-align:right;">
0.3271
</td>
<td style="text-align:right;">
0.2767
</td>
<td style="text-align:right;">
0.4423
</td>
<td style="text-align:right;">
0.2028
</td>
<td style="text-align:right;">
0.3788
</td>
<td style="text-align:right;">
0.2947
</td>
<td style="text-align:right;">
0.1984
</td>
<td style="text-align:right;">
0.2341
</td>
<td style="text-align:right;">
0.1306
</td>
<td style="text-align:right;">
0.4182
</td>
<td style="text-align:right;">
0.3835
</td>
<td style="text-align:right;">
0.1057
</td>
<td style="text-align:right;">
0.1840
</td>
<td style="text-align:right;">
0.1970
</td>
<td style="text-align:right;">
0.1674
</td>
<td style="text-align:right;">
0.0583
</td>
<td style="text-align:right;">
0.1401
</td>
<td style="text-align:right;">
0.1628
</td>
<td style="text-align:right;">
0.0621
</td>
<td style="text-align:right;">
0.0203
</td>
<td style="text-align:right;">
0.0530
</td>
<td style="text-align:right;">
0.0742
</td>
<td style="text-align:right;">
0.0409
</td>
<td style="text-align:right;">
0.0061
</td>
<td style="text-align:right;">
0.0125
</td>
<td style="text-align:right;">
0.0084
</td>
<td style="text-align:right;">
0.0089
</td>
<td style="text-align:right;">
0.0048
</td>
<td style="text-align:right;">
0.0094
</td>
<td style="text-align:right;">
0.0191
</td>
<td style="text-align:right;">
0.0140
</td>
<td style="text-align:right;">
0.0049
</td>
<td style="text-align:right;">
0.0052
</td>
<td style="text-align:right;">
0.0044
</td>
<td style="text-align:left;">
R
</td>
</tr>
<tr>
<td style="text-align:right;">
0.0262
</td>
<td style="text-align:right;">
0.0582
</td>
<td style="text-align:right;">
0.1099
</td>
<td style="text-align:right;">
0.1083
</td>
<td style="text-align:right;">
0.0974
</td>
<td style="text-align:right;">
0.2280
</td>
<td style="text-align:right;">
0.2431
</td>
<td style="text-align:right;">
0.3771
</td>
<td style="text-align:right;">
0.5598
</td>
<td style="text-align:right;">
0.6194
</td>
<td style="text-align:right;">
0.6333
</td>
<td style="text-align:right;">
0.7060
</td>
<td style="text-align:right;">
0.5544
</td>
<td style="text-align:right;">
0.5320
</td>
<td style="text-align:right;">
0.6479
</td>
<td style="text-align:right;">
0.6931
</td>
<td style="text-align:right;">
0.6759
</td>
<td style="text-align:right;">
0.7551
</td>
<td style="text-align:right;">
0.8929
</td>
<td style="text-align:right;">
0.8619
</td>
<td style="text-align:right;">
0.7974
</td>
<td style="text-align:right;">
0.6737
</td>
<td style="text-align:right;">
0.4293
</td>
<td style="text-align:right;">
0.3648
</td>
<td style="text-align:right;">
0.5331
</td>
<td style="text-align:right;">
0.2413
</td>
<td style="text-align:right;">
0.5070
</td>
<td style="text-align:right;">
0.8533
</td>
<td style="text-align:right;">
0.6036
</td>
<td style="text-align:right;">
0.8514
</td>
<td style="text-align:right;">
0.8512
</td>
<td style="text-align:right;">
0.5045
</td>
<td style="text-align:right;">
0.1862
</td>
<td style="text-align:right;">
0.2709
</td>
<td style="text-align:right;">
0.4232
</td>
<td style="text-align:right;">
0.3043
</td>
<td style="text-align:right;">
0.6116
</td>
<td style="text-align:right;">
0.6756
</td>
<td style="text-align:right;">
0.5375
</td>
<td style="text-align:right;">
0.4719
</td>
<td style="text-align:right;">
0.4647
</td>
<td style="text-align:right;">
0.2587
</td>
<td style="text-align:right;">
0.2129
</td>
<td style="text-align:right;">
0.2222
</td>
<td style="text-align:right;">
0.2111
</td>
<td style="text-align:right;">
0.0176
</td>
<td style="text-align:right;">
0.1348
</td>
<td style="text-align:right;">
0.0744
</td>
<td style="text-align:right;">
0.0130
</td>
<td style="text-align:right;">
0.0106
</td>
<td style="text-align:right;">
0.0033
</td>
<td style="text-align:right;">
0.0232
</td>
<td style="text-align:right;">
0.0166
</td>
<td style="text-align:right;">
0.0095
</td>
<td style="text-align:right;">
0.0180
</td>
<td style="text-align:right;">
0.0244
</td>
<td style="text-align:right;">
0.0316
</td>
<td style="text-align:right;">
0.0164
</td>
<td style="text-align:right;">
0.0095
</td>
<td style="text-align:right;">
0.0078
</td>
<td style="text-align:left;">
R
</td>
</tr>
<tr>
<td style="text-align:right;">
0.0100
</td>
<td style="text-align:right;">
0.0171
</td>
<td style="text-align:right;">
0.0623
</td>
<td style="text-align:right;">
0.0205
</td>
<td style="text-align:right;">
0.0205
</td>
<td style="text-align:right;">
0.0368
</td>
<td style="text-align:right;">
0.1098
</td>
<td style="text-align:right;">
0.1276
</td>
<td style="text-align:right;">
0.0598
</td>
<td style="text-align:right;">
0.1264
</td>
<td style="text-align:right;">
0.0881
</td>
<td style="text-align:right;">
0.1992
</td>
<td style="text-align:right;">
0.0184
</td>
<td style="text-align:right;">
0.2261
</td>
<td style="text-align:right;">
0.1729
</td>
<td style="text-align:right;">
0.2131
</td>
<td style="text-align:right;">
0.0693
</td>
<td style="text-align:right;">
0.2281
</td>
<td style="text-align:right;">
0.4060
</td>
<td style="text-align:right;">
0.3973
</td>
<td style="text-align:right;">
0.2741
</td>
<td style="text-align:right;">
0.3690
</td>
<td style="text-align:right;">
0.5556
</td>
<td style="text-align:right;">
0.4846
</td>
<td style="text-align:right;">
0.3140
</td>
<td style="text-align:right;">
0.5334
</td>
<td style="text-align:right;">
0.5256
</td>
<td style="text-align:right;">
0.2520
</td>
<td style="text-align:right;">
0.2090
</td>
<td style="text-align:right;">
0.3559
</td>
<td style="text-align:right;">
0.6260
</td>
<td style="text-align:right;">
0.7340
</td>
<td style="text-align:right;">
0.6120
</td>
<td style="text-align:right;">
0.3497
</td>
<td style="text-align:right;">
0.3953
</td>
<td style="text-align:right;">
0.3012
</td>
<td style="text-align:right;">
0.5408
</td>
<td style="text-align:right;">
0.8814
</td>
<td style="text-align:right;">
0.9857
</td>
<td style="text-align:right;">
0.9167
</td>
<td style="text-align:right;">
0.6121
</td>
<td style="text-align:right;">
0.5006
</td>
<td style="text-align:right;">
0.3210
</td>
<td style="text-align:right;">
0.3202
</td>
<td style="text-align:right;">
0.4295
</td>
<td style="text-align:right;">
0.3654
</td>
<td style="text-align:right;">
0.2655
</td>
<td style="text-align:right;">
0.1576
</td>
<td style="text-align:right;">
0.0681
</td>
<td style="text-align:right;">
0.0294
</td>
<td style="text-align:right;">
0.0241
</td>
<td style="text-align:right;">
0.0121
</td>
<td style="text-align:right;">
0.0036
</td>
<td style="text-align:right;">
0.0150
</td>
<td style="text-align:right;">
0.0085
</td>
<td style="text-align:right;">
0.0073
</td>
<td style="text-align:right;">
0.0050
</td>
<td style="text-align:right;">
0.0044
</td>
<td style="text-align:right;">
0.0040
</td>
<td style="text-align:right;">
0.0117
</td>
<td style="text-align:left;">
R
</td>
</tr>
<tr>
<td style="text-align:right;">
0.0762
</td>
<td style="text-align:right;">
0.0666
</td>
<td style="text-align:right;">
0.0481
</td>
<td style="text-align:right;">
0.0394
</td>
<td style="text-align:right;">
0.0590
</td>
<td style="text-align:right;">
0.0649
</td>
<td style="text-align:right;">
0.1209
</td>
<td style="text-align:right;">
0.2467
</td>
<td style="text-align:right;">
0.3564
</td>
<td style="text-align:right;">
0.4459
</td>
<td style="text-align:right;">
0.4152
</td>
<td style="text-align:right;">
0.3952
</td>
<td style="text-align:right;">
0.4256
</td>
<td style="text-align:right;">
0.4135
</td>
<td style="text-align:right;">
0.4528
</td>
<td style="text-align:right;">
0.5326
</td>
<td style="text-align:right;">
0.7306
</td>
<td style="text-align:right;">
0.6193
</td>
<td style="text-align:right;">
0.2032
</td>
<td style="text-align:right;">
0.4636
</td>
<td style="text-align:right;">
0.4148
</td>
<td style="text-align:right;">
0.4292
</td>
<td style="text-align:right;">
0.5730
</td>
<td style="text-align:right;">
0.5399
</td>
<td style="text-align:right;">
0.3161
</td>
<td style="text-align:right;">
0.2285
</td>
<td style="text-align:right;">
0.6995
</td>
<td style="text-align:right;">
1.0000
</td>
<td style="text-align:right;">
0.7262
</td>
<td style="text-align:right;">
0.4724
</td>
<td style="text-align:right;">
0.5103
</td>
<td style="text-align:right;">
0.5459
</td>
<td style="text-align:right;">
0.2881
</td>
<td style="text-align:right;">
0.0981
</td>
<td style="text-align:right;">
0.1951
</td>
<td style="text-align:right;">
0.4181
</td>
<td style="text-align:right;">
0.4604
</td>
<td style="text-align:right;">
0.3217
</td>
<td style="text-align:right;">
0.2828
</td>
<td style="text-align:right;">
0.2430
</td>
<td style="text-align:right;">
0.1979
</td>
<td style="text-align:right;">
0.2444
</td>
<td style="text-align:right;">
0.1847
</td>
<td style="text-align:right;">
0.0841
</td>
<td style="text-align:right;">
0.0692
</td>
<td style="text-align:right;">
0.0528
</td>
<td style="text-align:right;">
0.0357
</td>
<td style="text-align:right;">
0.0085
</td>
<td style="text-align:right;">
0.0230
</td>
<td style="text-align:right;">
0.0046
</td>
<td style="text-align:right;">
0.0156
</td>
<td style="text-align:right;">
0.0031
</td>
<td style="text-align:right;">
0.0054
</td>
<td style="text-align:right;">
0.0105
</td>
<td style="text-align:right;">
0.0110
</td>
<td style="text-align:right;">
0.0015
</td>
<td style="text-align:right;">
0.0072
</td>
<td style="text-align:right;">
0.0048
</td>
<td style="text-align:right;">
0.0107
</td>
<td style="text-align:right;">
0.0094
</td>
<td style="text-align:left;">
R
</td>
</tr>
<tr>
<td style="text-align:right;">
0.0286
</td>
<td style="text-align:right;">
0.0453
</td>
<td style="text-align:right;">
0.0277
</td>
<td style="text-align:right;">
0.0174
</td>
<td style="text-align:right;">
0.0384
</td>
<td style="text-align:right;">
0.0990
</td>
<td style="text-align:right;">
0.1201
</td>
<td style="text-align:right;">
0.1833
</td>
<td style="text-align:right;">
0.2105
</td>
<td style="text-align:right;">
0.3039
</td>
<td style="text-align:right;">
0.2988
</td>
<td style="text-align:right;">
0.4250
</td>
<td style="text-align:right;">
0.6343
</td>
<td style="text-align:right;">
0.8198
</td>
<td style="text-align:right;">
1.0000
</td>
<td style="text-align:right;">
0.9988
</td>
<td style="text-align:right;">
0.9508
</td>
<td style="text-align:right;">
0.9025
</td>
<td style="text-align:right;">
0.7234
</td>
<td style="text-align:right;">
0.5122
</td>
<td style="text-align:right;">
0.2074
</td>
<td style="text-align:right;">
0.3985
</td>
<td style="text-align:right;">
0.5890
</td>
<td style="text-align:right;">
0.2872
</td>
<td style="text-align:right;">
0.2043
</td>
<td style="text-align:right;">
0.5782
</td>
<td style="text-align:right;">
0.5389
</td>
<td style="text-align:right;">
0.3750
</td>
<td style="text-align:right;">
0.3411
</td>
<td style="text-align:right;">
0.5067
</td>
<td style="text-align:right;">
0.5580
</td>
<td style="text-align:right;">
0.4778
</td>
<td style="text-align:right;">
0.3299
</td>
<td style="text-align:right;">
0.2198
</td>
<td style="text-align:right;">
0.1407
</td>
<td style="text-align:right;">
0.2856
</td>
<td style="text-align:right;">
0.3807
</td>
<td style="text-align:right;">
0.4158
</td>
<td style="text-align:right;">
0.4054
</td>
<td style="text-align:right;">
0.3296
</td>
<td style="text-align:right;">
0.2707
</td>
<td style="text-align:right;">
0.2650
</td>
<td style="text-align:right;">
0.0723
</td>
<td style="text-align:right;">
0.1238
</td>
<td style="text-align:right;">
0.1192
</td>
<td style="text-align:right;">
0.1089
</td>
<td style="text-align:right;">
0.0623
</td>
<td style="text-align:right;">
0.0494
</td>
<td style="text-align:right;">
0.0264
</td>
<td style="text-align:right;">
0.0081
</td>
<td style="text-align:right;">
0.0104
</td>
<td style="text-align:right;">
0.0045
</td>
<td style="text-align:right;">
0.0014
</td>
<td style="text-align:right;">
0.0038
</td>
<td style="text-align:right;">
0.0013
</td>
<td style="text-align:right;">
0.0089
</td>
<td style="text-align:right;">
0.0057
</td>
<td style="text-align:right;">
0.0027
</td>
<td style="text-align:right;">
0.0051
</td>
<td style="text-align:right;">
0.0062
</td>
<td style="text-align:left;">
R
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="step-2--preparing-and-exploring-the-data" class="section level2">
<h2>Step 2- Preparing and exploring the data</h2>
<p>It is A data frame with 208 observations on 61 variables, all numerical and one (the Class) nominal.</p>
<pre><code>## number of rows and columns are: 208 61</code></pre>
<p>Lets check how many M classes and R classes Sonar data contain and check whether Sonar data contains any NA in its columns.</p>
<pre><code>## 
##   M   R 
## 111  97</code></pre>
<pre><code>##    V1    V2    V3    V4    V5    V6    V7    V8    V9   V10   V11   V12 
##     0     0     0     0     0     0     0     0     0     0     0     0 
##   V13   V14   V15   V16   V17   V18   V19   V20   V21   V22   V23   V24 
##     0     0     0     0     0     0     0     0     0     0     0     0 
##   V25   V26   V27   V28   V29   V30   V31   V32   V33   V34   V35   V36 
##     0     0     0     0     0     0     0     0     0     0     0     0 
##   V37   V38   V39   V40   V41   V42   V43   V44   V45   V46   V47   V48 
##     0     0     0     0     0     0     0     0     0     0     0     0 
##   V49   V50   V51   V52   V53   V54   V55   V56   V57   V58   V59   V60 
##     0     0     0     0     0     0     0     0     0     0     0     0 
## Class 
##     0</code></pre>
<p>Here, we want to manually take samples from our data to split <code>Sonar</code> into training and test sets</p>
<pre class="r"><code>SEED &lt;- 123
set.seed(SEED)
data &lt;- Sonar[base::sample(nrow(Sonar)), ] # shuffle data first
bound &lt;- floor(0.7 * nrow(data))
df_train &lt;- data[1:bound, ] 
df_test &lt;- data[(bound + 1):nrow(data), ]
cat(&quot;number of training and test samples are &quot;, nrow(df_train), nrow(df_test))</code></pre>
<pre><code>## number of training and test samples are  145 63</code></pre>
<p>Let’s examine if the train and test samples have properly splitted with the almost the same portion of <code>Class</code> labels</p>
<pre class="r"><code>cat(&quot;number of training classes: \n&quot;, base::table(df_train$Class)/nrow(df_train))</code></pre>
<pre><code>## number of training classes: 
##  0.5310345 0.4689655</code></pre>
<pre class="r"><code>cat(&quot;\n&quot;)</code></pre>
<pre class="r"><code>cat(&quot;number of test classes: \n&quot;, base::table(df_test$Class)/nrow(df_test))</code></pre>
<pre><code>## number of test classes: 
##  0.5396825 0.4603175</code></pre>
<p>To simplify our job, we can create the following data frames</p>
<pre class="r"><code>X_train &lt;- subset(df_train, select=-Class)
y_train &lt;- df_train$Class
X_test &lt;- subset(df_test, select=-Class) # exclude Class for prediction
y_test &lt;- df_test$Class</code></pre>
</div>
<div id="step-3-training-a-model-on-data" class="section level2">
<h2>Step 3 – Training a model on data</h2>
<p>Now, we are going to use knn function from class library with k=3</p>
<pre class="r"><code>model_knn &lt;- knn(train=X_train,
                 test=X_test,
                 cl=y_train,  # class labels
                 k=3)
model_knn</code></pre>
<pre><code>##  [1] M M M M R R M M M R M M M R M R R M M M M R M R R M R M R M M R M M M
## [36] M M M R R M M M M M R R R R R M M R M R R R R R R M R M
## Levels: M R</code></pre>
</div>
<div id="step-4-evaluate-the-model-performance" class="section level2">
<h2>Step 4 – Evaluate the model performance</h2>
<p>As you can see, model_knn with k=3 provides the above predictions for the test set X_test. Then, we can see how many classes have been correctly or incorrectly classified by comparing to the true labels as follows</p>
<pre class="r"><code>conf_mat &lt;- base::table(y_test, model_knn)
conf_mat</code></pre>
<pre><code>##       model_knn
## y_test  M  R
##      M 28  6
##      R  8 21</code></pre>
<p>To compute the accuracy, we sum up all the correctly classified observations (located in diagonal) and divide it by the total number of classes</p>
<pre><code>## Test accuracy:  0.7777778</code></pre>
<p>To assess whether k=3 is a good choice and see whether k=3</p>
<p>leads to overfitting/underfitting the data, we could use knn.cv which does the leave-one-out cross-validations for training set (i.e., it singles out a training sample one at a time and tries to view it as a new example and see what class label it assigns).</p>
<p>Below are the predicted classes for the training set using the leave-one-out cross-validation. Now, let’s examine its accuracy</p>
<pre class="r"><code>knn_loocv &lt;- knn.cv(train=X_train, cl=y_train, k=3)
knn_loocv</code></pre>
<pre><code>##   [1] R M R M M R M M M R M R M M M R R R R M M M M M M M R M R M M M M R M
##  [36] R M R R R R M R R R R M R R M M M M R R R M M M R R R R M M R M M R R
##  [71] M M M M R R M M M R M M M M M R M M M M R R M M R R R R R R M R M M M
## [106] R M R R M M M M M R M M M M M R R M M M R M M R M R R M M R R R R M R
## [141] M M R R M
## Levels: M R</code></pre>
<p>Lets create a confusion matrix to compute the accuracy of the training labels y_train and the cross-validated predictions knn_loocv, same as the above. What can you find from comparing the LOOCV accuracy and the test accuracy above?</p>
<pre class="r"><code>conf_mat_cv &lt;- base::table(y_train, knn_loocv)
conf_mat_cv</code></pre>
<pre><code>##        knn_loocv
## y_train  M  R
##       M 67 10
##       R 15 53</code></pre>
<pre class="r"><code>cat(&quot;LOOCV accuracy: &quot;, sum(diag(conf_mat_cv)) / sum(conf_mat_cv))</code></pre>
<pre><code>## LOOCV accuracy:  0.8275862</code></pre>
<p>The difference between the cross-validated accuracy and the test accuracy shows that, k=3 leads to overfitting. Perhaps we should change k</p>
<p>to lessen the overfitting.</p>
</div>
<div id="step-5-improve-the-performance-of-the-model" class="section level2">
<h2>Step 5 – Improve the performance of the model</h2>
<p>As noted earlier, we have not standardized (as part of preprocessing) our training and test sets. In the rest of the tutorial, we will see the effect of choosing a suitable k</p>
<p>through repeated cross-validations using caret library.</p>
<p>In a cross-validation procedure:</p>
<ul>
<li><p>The data is divided into the finite number of mutually exclusive subsets</p></li>
<li><p>Through each iteration, a subset is set aside for testing, and the remaining subsets are used as the training set</p></li>
<li><p>The subset that was set aside is used as the test set (prediction)</p></li>
</ul>
<p>This is a method of cross-referencing the model built using its own data.</p>
<pre class="r"><code>SEED &lt;- 2016
set.seed(SEED)
# create the training data 70% of the overall Sonar data.
in_train &lt;- createDataPartition(Sonar$Class, p=0.7, list=FALSE) # create training indices
ndf_train &lt;- Sonar[in_train, ]
ndf_test &lt;- Sonar[-in_train, ]</code></pre>
<p>Here, we specify the cross-validation method we want to use to find the best k in grid search. Later, we use the built-in plot function to assess the changes in accuracy for different choices of k.</p>
<pre class="r"><code># lets create a function setup to do 5-fold cross-validation with 2 repeat.
ctrl &lt;- trainControl(method=&quot;repeatedcv&quot;, number=5, repeats=2)

nn_grid &lt;- expand.grid(k=c(1,3,5,7))
nn_grid</code></pre>
<pre><code>##   k
## 1 1
## 2 3
## 3 5
## 4 7</code></pre>
<pre class="r"><code>set.seed(SEED)

best_knn &lt;- train(Class~., data=ndf_train,
                  method=&quot;knn&quot;,
                  trControl=ctrl, 
                  preProcess = c(&quot;center&quot;, &quot;scale&quot;),  # standardize
                  tuneGrid=nn_grid)
best_knn</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 146 samples
##  60 predictor
##   2 classes: &#39;M&#39;, &#39;R&#39; 
## 
## Pre-processing: centered (60), scaled (60) 
## Resampling: Cross-Validated (5 fold, repeated 2 times) 
## Summary of sample sizes: 116, 116, 117, 117, 118, 116, ... 
## Resampling results across tuning parameters:
## 
##   k  Accuracy   Kappa    
##   1  0.8593432  0.7152417
##   3  0.8329310  0.6601456
##   5  0.7846305  0.5602652
##   7  0.7608210  0.5081680
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was k = 1.</code></pre>
<p>So seemingly, k=1 has the highest accuracy from repeated cross-validation.</p>
<div id="optional-exercise" class="section level3">
<h3>(Optional) Exercise</h3>
<p>Try to do dimensionality reduction as part of preprocess to achieve higher testing accuracy than above. This may not have a definite solution and it depends on how hard you try!</p>
<p>If you are going to use caret, here are the available preprocess options with explanations.</p>
<p>Use the above best_knn to make predictions on the test set (remeber to remove the Class for prediction). Then create the much better version of confusion matrix with confusionMatrix function from caret and examine the accuracy and its %95 confidence interval.</p>
<p>In fact, the above result indicates k=1 (as could be guessed) is also overfitting, though it might be a better option than k=3. Since the initial dimension of our data is high (61</p>
<p>is considered high!), then you might have suspected the better approach, as we said at the beginning of tutorial, is to preform dimensionality reduction as part of preprocessing.</p>
</div>
<div id="optional-exercise-1" class="section level3">
<h3>(Optional) Exercise</h3>
<p>Try to do dimensionality reduction as part of preprocess to achieve higher testing accuracy than above. This may not have a definite solution and it depends on how hard you try!</p>
<p>If you are going to use caret, here are the available preprocess options with explanations.</p>
<pre class="r"><code>SEED &lt;- 123 
set.seed(SEED) 
ctrl &lt;- trainControl(method=&quot;repeatedcv&quot;, number=5, repeats=5) 
nn_grid &lt;- expand.grid(k=c(1, 3, 5, 7)) 
best_knn_reduced &lt;- train( Class~., data=ndf_train, method=&quot;knn&quot;, 
                            trControl=ctrl, preProcess=c(&quot;center&quot;, &quot;scale&quot;,&quot;YeoJohnson&quot;))
X_test &lt;- subset(ndf_test, select=-Class) 
pred_reduced &lt;- predict(best_knn_reduced, newdata=X_test, model=&quot;best&quot;) 
conf_mat_best_reduced &lt;- confusionMatrix(ndf_test$Class, pred_reduced) 
conf_mat_best_reduced </code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  M  R
##          M 29  4
##          R  9 20
##                                           
##                Accuracy : 0.7903          
##                  95% CI : (0.6682, 0.8834)
##     No Information Rate : 0.6129          
##     P-Value [Acc &gt; NIR] : 0.002277        
##                                           
##                   Kappa : 0.5744          
##  Mcnemar&#39;s Test P-Value : 0.267257        
##                                           
##             Sensitivity : 0.7632          
##             Specificity : 0.8333          
##          Pos Pred Value : 0.8788          
##          Neg Pred Value : 0.6897          
##              Prevalence : 0.6129          
##          Detection Rate : 0.4677          
##    Detection Prevalence : 0.5323          
##       Balanced Accuracy : 0.7982          
##                                           
##        &#39;Positive&#39; Class : M               
## </code></pre>
</div>
</div>

      </div>

      


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="../../tags/notes">notes</a>
  
  <a class="btn btn-primary btn-outline" href="../../tags/learning">learning</a>
  
</div>



    </div>
  </div>

</article>






<div class="article-container">
  
<section id="comments">
  <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "g29s" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


</div>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2017 GAURAV SATAV &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    <script id="dsq-count-scr" src="//g29s.disqus.com/count.js" async></script>
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    
    <script src="../../js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

